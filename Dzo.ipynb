{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUDUSD-2000-2020-15m.csv', 'EURCHF-2000-2020-15m.csv', 'EURJPY-2000-2020-15m.csv', 'EURUSD-2000-2020-15m.csv', 'EUR_USD Historical Data.csv', 'USDCAD-2000-2020-15m.csv', 'USDCHF-2000-2020-15m.csv', 'USDJPY-2000-2020-15m.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./datasets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FXDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                    data_dir,\n",
    "                    batch_size,\n",
    "                    length,\n",
    "                    source_len,\n",
    "                    target_len,\n",
    "                    step):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.length = length\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "        self.step = step\n",
    "        \n",
    "    def split_sequence(source,\n",
    "                       target,\n",
    "                       source_len,\n",
    "                       target_len,\n",
    "                       step,\n",
    "                       target_start_next):\n",
    "        \"\"\" Split sequence with sliding window into\n",
    "            sequences of context features and target.\n",
    "            Args:\n",
    "                source (np.array): Source sequence\n",
    "                target (np.array): Target sequence\n",
    "                source_len (int): Length of input sequence.\n",
    "                target_len (int): Length of target sequence.\n",
    "                target_start_next (bool): If True, target sequence\n",
    "                        starts on the next time step of last step of source\n",
    "                        sequence. If False, target sequence starts at the\n",
    "                        same time step of source sequence.\n",
    "            Return:\n",
    "                X (np.array): sequence of features\n",
    "                y (np.array): sequence of targets\n",
    "        \"\"\"\n",
    "        assert len(source) == len(target), \\\n",
    "                'Source sequence and target sequence should have the same length.'\n",
    "\n",
    "        X, y = list(), list()\n",
    "        if not target_start_next:\n",
    "            target = np.vstack((np.zeros(target.shape[1], dtype=target.dtype), target))\n",
    "        for i in range(0, len(source), step):\n",
    "            # Find the end of this pattern:\n",
    "            src_end = i + source_len\n",
    "            tgt_end = src_end + target_len\n",
    "            # Check if beyond the length of sequence:\n",
    "            if tgt_end > len(target):\n",
    "                break\n",
    "            # Split sequences:\n",
    "            X.append(source[i:src_end, :])\n",
    "            y.append(target[src_end:tgt_end, :])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        df = pd.read_csv(self.data_dir,parse_dates=['DATE_TIME'])\n",
    "        self.data = df.iloc[:,1:]\n",
    "        self.src,self.tgt \n",
    "    = split_sequence(data,data,self.source_len,self.target_len,self.step,True) # 192 is 2 days\n",
    "\n",
    "        \n",
    "    def setup(self):\n",
    "        test_idx = int(len(self.src) * 0.7)\n",
    "        self.src, self.src_test, self.tgt, self.tgt_test \\\n",
    "            = self.src[:test_idx], self.src[test_idx:], self.tgt[:test_idx], self.tgt[test_idx:]\n",
    "        src_train, src_val, tgt_train, tgt_val \\\n",
    "            = train_test_split(self.src, self.tgt, test_size=0.25, random_state=1)\n",
    "        \n",
    "    def train_dataloader(self)\n",
    "    def val_dataloader(self)\n",
    "    def test_dataloader(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FXModule(pl.LightningModule):\n",
    "    def __init__()\n",
    "    def forward()\n",
    "    def configure_optimizers()\n",
    "    def training_step()\n",
    "    def validation_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rich_net = FXModule()\n",
    "get_rich_dm = FXDataModule()\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model=get_rich_net,datamodule=get_rich_dm,fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
